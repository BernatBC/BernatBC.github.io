<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Mini-Hackathon on BernatBC</title><link>https://www.bernatbc.tk/tags/mini-hackathon/</link><description>Recent content in Mini-Hackathon on BernatBC</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Thu, 13 Mar 2025 06:00:23 +0600</lastBuildDate><atom:link href="https://www.bernatbc.tk/tags/mini-hackathon/index.xml" rel="self" type="application/rss+xml"/><item><title>LLM Chat RAG</title><link>https://www.bernatbc.tk/posts/education/llm-chat-rag/</link><pubDate>Thu, 13 Mar 2025 06:00:23 +0600</pubDate><guid>https://www.bernatbc.tk/posts/education/llm-chat-rag/</guid><description>&lt;h1 id="llm-chat-rag---cli-interface">LLM Chat RAG - CLI Interface&lt;/h1>
&lt;h2 id="overview">Overview&lt;/h2>
&lt;p>The &lt;strong>LLM Chat RAG&lt;/strong> (Retriever-Augmented Generation) is a Command Line Interface (CLI) tool that allows you to interact with documents stored in a ChromaDB database using OpenAI&amp;rsquo;s GPT-4o-mini model. This system provides a way to query documents for relevant information, retrieve context, and generate AI-driven responses based on that context.&lt;/p>
&lt;h2 id="features">Features&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Retriever-Augmented Generation (RAG):&lt;/strong> Retrieve context from a database and use it to generate more accurate and informative responses.&lt;/li>
&lt;li>&lt;strong>OpenAI GPT-4o-mini Model:&lt;/strong> Uses OpenAI&amp;rsquo;s GPT-4o-mini to generate answers based on the retrieved context.&lt;/li>
&lt;li>&lt;strong>ChromaDB Integration:&lt;/strong> Uses ChromaDB for efficient document retrieval and context management.&lt;/li>
&lt;li>&lt;strong>Command-line interface:&lt;/strong> Interact with the system through an intuitive CLI, allowing commands such as &lt;code>/help&lt;/code>, &lt;code>/exit&lt;/code>, and &lt;code>/sources&lt;/code>.&lt;/li>
&lt;/ul>
&lt;h2 id="prerequisites">Prerequisites&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Python 3.x&lt;/strong>: Ensure Python 3.6 or later is installed.&lt;/li>
&lt;li>&lt;strong>OpenAI API Key&lt;/strong>: You must have an OpenAI API key to use the GPT model.&lt;/li>
&lt;li>&lt;strong>ChromaDB&lt;/strong>: A local or cloud-based ChromaDB instance for document storage and retrieval.&lt;/li>
&lt;/ul>
&lt;h2 id="setup">Setup&lt;/h2>
&lt;h3 id="1-install-dependencies">1. Install Dependencies&lt;/h3>
&lt;p>Install required dependencies via &lt;code>pip&lt;/code>:&lt;/p></description></item><item><title>Database Embedding</title><link>https://www.bernatbc.tk/posts/education/database-embedding/</link><pubDate>Thu, 06 Mar 2025 06:00:23 +0600</pubDate><guid>https://www.bernatbc.tk/posts/education/database-embedding/</guid><description>&lt;h1 id="markdown-to-chromadb-indexer">Markdown to ChromaDB Indexer&lt;/h1>
&lt;p>This tool indexes markdown files into ChromaDB for efficient semantic search capabilities, with support for both default embeddings and OpenAI&amp;rsquo;s text-embedding-3-small model for enhanced search quality.&lt;/p>
&lt;h2 id="features">Features&lt;/h2>
&lt;ul>
&lt;li>Flexible embedding options:
&lt;ul>
&lt;li>Default ChromaDB embeddings (no API key required)&lt;/li>
&lt;li>Optional OpenAI text-embedding-3-small model for enhanced quality&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Recursively processes markdown files in a directory&lt;/li>
&lt;li>Intelligent text chunking with configurable size and overlap&lt;/li>
&lt;li>Sentence-aware splitting to maintain context&lt;/li>
&lt;li>Extracts and preserves frontmatter metadata&lt;/li>
&lt;li>Converts markdown to searchable text&lt;/li>
&lt;li>Stores documents with their metadata in ChromaDB&lt;/li>
&lt;li>Supports semantic search queries&lt;/li>
&lt;li>Batch processing for large datasets&lt;/li>
&lt;/ul>
&lt;h2 id="installation">Installation&lt;/h2>
&lt;ol>
&lt;li>Install the required dependencies:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>pip install -r requirements.txt
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="2">
&lt;li>(Optional) Set up OpenAI embeddings:
&lt;ul>
&lt;li>Create a &lt;code>.env&lt;/code> file with your OpenAI API key:&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>OPENAI_API_KEY&lt;span style="color:#f92672">=&lt;/span>your_api_key_here
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="usage">Usage&lt;/h2>
&lt;p>To index your markdown files:&lt;/p></description></item><item><title>Web to Markdown</title><link>https://www.bernatbc.tk/posts/education/web-to-markdown/</link><pubDate>Thu, 27 Feb 2025 06:00:23 +0600</pubDate><guid>https://www.bernatbc.tk/posts/education/web-to-markdown/</guid><description>&lt;h1 id="web-to-markdown">Web-to-Markdown&lt;/h1>
&lt;p>The purpose of this project is to be able to convert the information from any website into a Markdown bucket.&lt;/p>
&lt;h2 id="usage">Usage&lt;/h2>
&lt;p>This website has a UI with a text field in the middle. Enter the base URL of the website you want to extract information from and it will automatically find all the attached links to it and also extract information from them.&lt;/p>
&lt;p>To extract this information we get the HTML using the library trafilatura and parse it using BeautifulSoup and html2text.&lt;/p></description></item><item><title>Subtitle Generator</title><link>https://www.bernatbc.tk/posts/education/subtitle-generator/</link><pubDate>Thu, 20 Feb 2025 06:00:23 +0600</pubDate><guid>https://www.bernatbc.tk/posts/education/subtitle-generator/</guid><description>&lt;h1 id="subtitle-generator">Subtitle Generator&lt;/h1>
&lt;video class="video-player" id="video-183" playsinline controls>
&lt;source src="subtitle_generator.mp4" type="video/mp4" />
&lt;/video>
&lt;p>This project provides a web application that automatically generates subtitles (in SRT or VTT format) from audio files. It leverages the power of OpenAI&amp;rsquo;s Whisper speech recognition model for transcription and pyannote.audio for speaker diarization, all wrapped in a user-friendly FastAPI web interface.&lt;/p>
&lt;h2 id="features">Features&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Web Interface:&lt;/strong> A clean, simple HTML interface for uploading audio files. No complex command-line usage is required.&lt;/li>
&lt;li>&lt;strong>Multiple Audio Formats:&lt;/strong> Supports &lt;code>.wav&lt;/code>, &lt;code>.mp3&lt;/code>, &lt;code>.m4a&lt;/code>, and &lt;code>.flac&lt;/code> files. Automatic conversion to WAV is handled internally.&lt;/li>
&lt;li>&lt;strong>Speaker Diarization:&lt;/strong> Identifies different speakers in the audio and includes speaker labels in the generated subtitles.&lt;/li>
&lt;li>&lt;strong>Subtitle Formats:&lt;/strong> Generates subtitles in either &lt;code>.srt&lt;/code> (SubRip) or &lt;code>.vtt&lt;/code> (WebVTT) format, selectable via the web interface.&lt;/li>
&lt;li>&lt;strong>Fast and Efficient:&lt;/strong> Utilizes a dynamically selected Whisper model (from &lt;code>tiny&lt;/code> to &lt;code>large&lt;/code>) based on your system&amp;rsquo;s available RAM and VRAM (GPU memory), optimizing for performance and accuracy.&lt;/li>
&lt;li>&lt;strong>Easy Deployment:&lt;/strong> Can be run directly with Uvicorn or easily deployed using Docker and Docker Compose.&lt;/li>
&lt;li>&lt;strong>Well-Defined API:&lt;/strong> A single &lt;code>/upload-audio/&lt;/code> endpoint handles file uploads and subtitle generation, with clear request and response formats.&lt;/li>
&lt;li>&lt;strong>File Size Limit:&lt;/strong> The maximum upload file is limited to 50MB.&lt;/li>
&lt;/ul>
&lt;h2 id="requirements">Requirements&lt;/h2>
&lt;p>Before you get started, make sure you have the following:&lt;/p></description></item></channel></rss>