<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Python on BernatBC</title><link>https://www.bernatbc.tk/tags/python/</link><description>Recent content in Python on BernatBC</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Thu, 06 Mar 2025 06:00:23 +0600</lastBuildDate><atom:link href="https://www.bernatbc.tk/tags/python/index.xml" rel="self" type="application/rss+xml"/><item><title>Database Embedding</title><link>https://www.bernatbc.tk/posts/education/database-embedding/</link><pubDate>Thu, 06 Mar 2025 06:00:23 +0600</pubDate><guid>https://www.bernatbc.tk/posts/education/database-embedding/</guid><description>&lt;h1 id="markdown-to-chromadb-indexer">Markdown to ChromaDB Indexer&lt;/h1>
&lt;p>This tool indexes markdown files into ChromaDB for efficient semantic search capabilities, with support for both default embeddings and OpenAI&amp;rsquo;s text-embedding-3-small model for enhanced search quality.&lt;/p>
&lt;h2 id="features">Features&lt;/h2>
&lt;ul>
&lt;li>Flexible embedding options:
&lt;ul>
&lt;li>Default ChromaDB embeddings (no API key required)&lt;/li>
&lt;li>Optional OpenAI text-embedding-3-small model for enhanced quality&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Recursively processes markdown files in a directory&lt;/li>
&lt;li>Intelligent text chunking with configurable size and overlap&lt;/li>
&lt;li>Sentence-aware splitting to maintain context&lt;/li>
&lt;li>Extracts and preserves frontmatter metadata&lt;/li>
&lt;li>Converts markdown to searchable text&lt;/li>
&lt;li>Stores documents with their metadata in ChromaDB&lt;/li>
&lt;li>Supports semantic search queries&lt;/li>
&lt;li>Batch processing for large datasets&lt;/li>
&lt;/ul>
&lt;h2 id="installation">Installation&lt;/h2>
&lt;ol>
&lt;li>Install the required dependencies:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>pip install -r requirements.txt
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="2">
&lt;li>(Optional) Set up OpenAI embeddings:
&lt;ul>
&lt;li>Create a &lt;code>.env&lt;/code> file with your OpenAI API key:&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>OPENAI_API_KEY&lt;span style="color:#f92672">=&lt;/span>your_api_key_here
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="usage">Usage&lt;/h2>
&lt;p>To index your markdown files:&lt;/p></description></item><item><title>Web to Markdown</title><link>https://www.bernatbc.tk/posts/education/web-to-markdown/</link><pubDate>Thu, 27 Feb 2025 06:00:23 +0600</pubDate><guid>https://www.bernatbc.tk/posts/education/web-to-markdown/</guid><description>&lt;h1 id="web-to-markdown">Web-to-Markdown&lt;/h1>
&lt;p>The purpose of this project is to be able to convert the information from any website into a Markdown bucket.&lt;/p>
&lt;h2 id="usage">Usage&lt;/h2>
&lt;p>This website has a UI with a text field in the middle. Enter the base URL of the website you want to extract information from and it will automatically find all the attached links to it and also extract information from them.&lt;/p>
&lt;p>To extract this information we get the HTML using the library trafilatura and parse it using BeautifulSoup and html2text.&lt;/p></description></item><item><title>Subtitle Generator</title><link>https://www.bernatbc.tk/posts/education/subtitle-generator/</link><pubDate>Thu, 20 Feb 2025 06:00:23 +0600</pubDate><guid>https://www.bernatbc.tk/posts/education/subtitle-generator/</guid><description>&lt;h1 id="subtitle-generator">Subtitle Generator&lt;/h1>
&lt;video class="video-player" id="video-119" playsinline controls>
&lt;source src="subtitle_generator.mp4" type="video/mp4" />
&lt;/video>
&lt;p>This project provides a web application that automatically generates subtitles (in SRT or VTT format) from audio files. It leverages the power of OpenAI&amp;rsquo;s Whisper speech recognition model for transcription and pyannote.audio for speaker diarization, all wrapped in a user-friendly FastAPI web interface.&lt;/p>
&lt;h2 id="features">Features&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Web Interface:&lt;/strong> A clean, simple HTML interface for uploading audio files. No complex command-line usage is required.&lt;/li>
&lt;li>&lt;strong>Multiple Audio Formats:&lt;/strong> Supports &lt;code>.wav&lt;/code>, &lt;code>.mp3&lt;/code>, &lt;code>.m4a&lt;/code>, and &lt;code>.flac&lt;/code> files. Automatic conversion to WAV is handled internally.&lt;/li>
&lt;li>&lt;strong>Speaker Diarization:&lt;/strong> Identifies different speakers in the audio and includes speaker labels in the generated subtitles.&lt;/li>
&lt;li>&lt;strong>Subtitle Formats:&lt;/strong> Generates subtitles in either &lt;code>.srt&lt;/code> (SubRip) or &lt;code>.vtt&lt;/code> (WebVTT) format, selectable via the web interface.&lt;/li>
&lt;li>&lt;strong>Fast and Efficient:&lt;/strong> Utilizes a dynamically selected Whisper model (from &lt;code>tiny&lt;/code> to &lt;code>large&lt;/code>) based on your system&amp;rsquo;s available RAM and VRAM (GPU memory), optimizing for performance and accuracy.&lt;/li>
&lt;li>&lt;strong>Easy Deployment:&lt;/strong> Can be run directly with Uvicorn or easily deployed using Docker and Docker Compose.&lt;/li>
&lt;li>&lt;strong>Well-Defined API:&lt;/strong> A single &lt;code>/upload-audio/&lt;/code> endpoint handles file uploads and subtitle generation, with clear request and response formats.&lt;/li>
&lt;li>&lt;strong>File Size Limit:&lt;/strong> The maximum upload file is limited to 50MB.&lt;/li>
&lt;/ul>
&lt;h2 id="requirements">Requirements&lt;/h2>
&lt;p>Before you get started, make sure you have the following:&lt;/p></description></item><item><title>Object Tracker</title><link>https://www.bernatbc.tk/posts/education/objecttracker/</link><pubDate>Fri, 23 Jun 2023 06:00:23 +0600</pubDate><guid>https://www.bernatbc.tk/posts/education/objecttracker/</guid><description>&lt;h2 id="the-statement">The statement&lt;/h2>
&lt;p>
&lt;a href="https://amoudgl.github.io/tlp/" target="_blank" rel="noopener">Long-Term Visual Object Tracking Benchmark&lt;/a> is a dataset to benchmark object tracking algorithms. We were asked to implement four different algorithms. Two using tracking techniques, and two using recognition. For each technique, we had to implement one from scratch (an algorithm made for us) and another one extracted from the internet.&lt;/p>
&lt;p>Given a series of frames and a bounding box corresponding to the object to track, the algorithm should follow the object. To evaluate the precision, we used the overlapping ratio between the computed bounding box and the optimal bounding box (which was given via a txt file).&lt;/p></description></item><item><title>Î»-Calculus Telegram Bot</title><link>https://www.bernatbc.tk/posts/education/lambdacalculustelegrambot/</link><pubDate>Tue, 13 Jun 2023 06:00:23 +0600</pubDate><guid>https://www.bernatbc.tk/posts/education/lambdacalculustelegrambot/</guid><description>&lt;h2 id="the-statement">The statement&lt;/h2>
&lt;p>We were asked to make a lambda-calculus interpreter created by
&lt;a href="https://en.wikipedia.org/wiki/Alonzo_Church" target="_blank" rel="noopener">Alonzo Church&lt;/a>. This interpreter had also to support the definition and use of macros, a variable name for another expression. Those macros had to be evaluated in an infix (if it&amp;rsquo;s a symbol) or a prefix mode (otherwise). On top of that, our interpreter had to run in a
&lt;a href="https://telegram.org/" target="_blank" rel="noopener">Telegram&lt;/a> chat. Finally, we had to add the capability to print our expression as a tree in an image.&lt;/p></description></item></channel></rss>