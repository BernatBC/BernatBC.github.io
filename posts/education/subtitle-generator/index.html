<!doctype html><html lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Subtitle Generator - BernatBC</title>
<link rel=stylesheet href=https://bernatbc.tk/styles/style.min.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/katex.min.css integrity=sha384-zh0CIslj+VczCZtlzBcjt5ppRcsAmDnRem7ESsYwWwg3m/OaJ2l4x7YBZl9Kxxib crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/katex.min.js integrity=sha384-Rma6DA2IPUwhNxmrB/7S3Tno0YY7sFu9WSYMCuulLhIqYSGZ2gKCJWIqhBWqMQfh crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/contrib/auto-render.min.js integrity=sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh crossorigin=anonymous onload=renderMathInElement(document.body)></script></head><body class=dark-theme><div class=page-wrapper><nav class=navbar><div class=navbar-container><button id=navbar-toggle class=navbar-toggle>
<i class="fas fa-bars"></i></button><div class=navbar-nav id=navbar-nav><ul><li><a href=/#profile class=nav-link><i class="fas fa-user"></i> Profile</a></li><li><a href=/#skills class=nav-link><i class="fas fa-code"></i> Skills</a></li><li><a href=/#experiences class=nav-link><i class="fas fa-briefcase"></i> Experiences</a></li><li><a href=/#education class=nav-link><i class="fas fa-graduation-cap"></i> Education</a></li><li><a href=/#projects class=nav-link><i class="fas fa-project-diagram"></i> Open Source Projects</a></li><li><a href=/#recent-posts class=nav-link><i class="fas fa-newspaper"></i> Recent Posts</a></li><li><a href=/posts class="nav-link active"><i class="fas fa-pen"></i> All Posts</a></li></ul></div></div></nav><div class=content-wrapper><aside class=toc-container><div class=toc><h3 class=toc-title><i class="fas fa-list"></i> Table of Contents</h3><div id=toc-content class=toc-content></div></div></aside><div class=main-content><div class=container><article class=post-single><header class=post-header><h1 class=section-title>Subtitle Generator</h1><div class=post-meta><div class=post-meta-top><span class=post-date><i class="far fa-calendar-alt"></i> February 20, 2025</span></div><div class=post-tags><span class=post-tag>AI</span>
<span class=post-tag>Education</span>
<span class=post-tag>Mini-hackathon</span>
<span class=post-tag>Python</span></div></div><div class=post-featured-image><img src=/posts/education/subtitle-generator/hero.png alt="Subtitle Generator"></div></header><div class=post-content><h1 id=subtitle-generator>Subtitle Generator</h1><div class=video-container><video class=video-player id=video-1757089013384588028 playsinline controls>
<source src=subtitle_generator.mp4 type=video/mp4></video></div><p>This project provides a web application that automatically generates subtitles (in SRT or VTT format) from audio files. It leverages the power of OpenAI&rsquo;s Whisper speech recognition model for transcription and pyannote.audio for speaker diarization, all wrapped in a user-friendly FastAPI web interface.</p><h2 id=features>Features</h2><ul><li><strong>Web Interface:</strong> A clean, simple HTML interface for uploading audio files. No complex command-line usage is required.</li><li><strong>Multiple Audio Formats:</strong> Supports <code>.wav</code>, <code>.mp3</code>, <code>.m4a</code>, and <code>.flac</code> files. Automatic conversion to WAV is handled internally.</li><li><strong>Speaker Diarization:</strong> Identifies different speakers in the audio and includes speaker labels in the generated subtitles.</li><li><strong>Subtitle Formats:</strong> Generates subtitles in either <code>.srt</code> (SubRip) or <code>.vtt</code> (WebVTT) format, selectable via the web interface.</li><li><strong>Fast and Efficient:</strong> Utilizes a dynamically selected Whisper model (from <code>tiny</code> to <code>large</code>) based on your system&rsquo;s available RAM and VRAM (GPU memory), optimizing for performance and accuracy.</li><li><strong>Easy Deployment:</strong> Can be run directly with Uvicorn or easily deployed using Docker and Docker Compose.</li><li><strong>Well-Defined API:</strong> A single <code>/upload-audio/</code> endpoint handles file uploads and subtitle generation, with clear request and response formats.</li><li><strong>File Size Limit:</strong> The maximum upload file is limited to 50MB.</li></ul><h2 id=requirements>Requirements</h2><p>Before you get started, make sure you have the following:</p><ol><li><p><strong>Hugging Face Account and Token:</strong></p><ul><li>You <em>must</em> have a Hugging Face account. Create one at <a href=https://huggingface.co/join>Hugging Face</a>.</li><li>Generate an access token (with at least read access) from your <a href=https://huggingface.co/settings/tokens>Hugging Face settings</a>. You&rsquo;ll need this token for both direct execution and Docker deployment.</li><li><strong>Accept User Agreements:</strong> <em>Crucially</em>, you need to visit <em>both</em> of these pages and accept the user agreements:<ul><li><a href=https://huggingface.co/pyannote/speaker-diarization>pyannote/speaker-diarization</a></li><li><a href=https://huggingface.co/pyannote/segmentation>pyannote/segmentation</a></li></ul></li><li>Store your Hugging Face token into a <code>.env</code> file, or store it in the environment variable HF_AUTH_TOKEN.</li></ul></li><li><p><strong>Python:</strong> Python 3.7 or higher is recommended. Check your version:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>python --version  <span style=color:#75715e># or python3 --version</span>
</span></span></code></pre></div></li><li><p><strong>FFmpeg:</strong> This is essential for audio processing. Install it using your system&rsquo;s package manager:</p><ul><li><p><strong>Ubuntu/Debian:</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sudo apt update
</span></span><span style=display:flex><span>sudo apt install ffmpeg
</span></span></code></pre></div></li><li><p><strong>macOS (using Homebrew):</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>brew install ffmpeg
</span></span></code></pre></div></li><li><p><strong>Windows:</strong> Download a pre-built binary from a trusted source (e.g., <a href=https://www.gyan.dev/ffmpeg/builds/>gyan.dev</a>). Add the <code>bin</code> directory containing <code>ffmpeg.exe</code> and <code>ffprobe.exe</code> to your system&rsquo;s PATH environment variable. <em>Test this thoroughly</em> by opening a new command prompt and typing <code>ffmpeg -version</code>.</p></li><li><p><strong>Verification (all platforms):</strong> After installation, <em>always</em> verify:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>ffmpeg -version
</span></span></code></pre></div></li></ul></li><li><p><strong>Python Packages:</strong> Install the required libraries via pip:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>pip install -r requirements.txt
</span></span></code></pre></div><p>Ensure your <code>requirements.txt</code> file contains:</p><pre tabindex=0><code>uvicorn
fastapi
python-multipart
pydub
openai-whisper
pyannote.audio
dotenv
psutil
torch
</code></pre></li></ol><h2 id=setup-and-running-the-application>Setup and Running the Application</h2><h3 id=option-1-running-directly-without-docker-recommended-if-cuda>Option 1: Running Directly without Docker (Recommended if CUDA)</h3><ol><li><p><strong>Clone the Repository (Optional):</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>git clone &lt;repository_url&gt;
</span></span><span style=display:flex><span>cd &lt;repository_directory&gt;
</span></span></code></pre></div><p>(Skip this if you have the files directly.)</p></li><li><p><strong>Create <code>index.html</code>:</strong> Make sure the <code>index.html</code> file is in the same directory as <code>main.py</code>.</p></li><li><p><strong>Create <code>.env</code> file:</strong> Create a file called <code>.env</code> in the main directory with this content:</p><pre tabindex=0><code>HF_AUTH_TOKEN=&lt;your_huggingface_token&gt;
</code></pre></li><li><p><strong>Run the Application with Uvicorn:</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>uvicorn main:app --reload --host 0.0.0.0 --port <span style=color:#ae81ff>8080</span>
</span></span></code></pre></div><ul><li><code>main:app</code>: Adjust if your Python file or app instance have different names.</li><li><code>--reload</code>: Enables auto-reloading on code changes (great for development).</li><li><code>--host 0.0.0.0</code>: Allows access from other devices on your network. Remove for local-only access.</li><li><code>--port 8080</code>: Change if you need a different port.</li></ul></li><li><p><strong>Access the Application:</strong> Open your browser:</p><ul><li><strong>Locally:</strong> <code>http://localhost:8080</code></li><li><strong>From another device:</strong> <code>http://&lt;your_server_ip>:8080</code></li></ul></li></ol><h3 id=option-2-docker-compose-deployment-recommended-if-no-cuda>Option 2: Docker Compose Deployment (Recommended if no CUDA)</h3><p>Docker Compose simplifies deployment by managing the application and its dependencies in a container.</p><ol><li><p><strong>Install Docker and Docker Compose:</strong> Follow the official instructions for your operating system: <a href=https://docs.docker.com/get-docker/>Docker Installation</a> and <a href=https://docs.docker.com/compose/install/>Docker Compose Installation</a>.</p></li><li><p><strong>Create a <code>.env</code> file:</strong> Create a <code>.env</code> file in the <em>same directory</em> as your <code>compose.yaml</code> file. Add your Hugging Face token:</p><pre tabindex=0><code>HF_AUTH_TOKEN=&lt;your_huggingface_token&gt;
</code></pre><p><em>Important:</em> Do <em>not</em> commit your <code>.env</code> file to version control.</p></li><li><p><strong>Build and Run:</strong> From the directory containing <code>compose.yaml</code>, run:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>docker compose up --build
</span></span></code></pre></div><p>The <code>--build</code> flag forces a rebuild of the image, ensuring any changes to your code or <code>requirements.txt</code> are included. You can omit <code>--build</code> on subsequent runs if you haven&rsquo;t made changes. Use <code>docker compose up -d --build</code> to run in detached mode.</p></li><li><p><strong>Access the Application:</strong> Same as above (http://localhost:8080 or http://&lt;your_server_ip>:8080).</p></li><li><p><strong>Stop the application</strong>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>docker compose down
</span></span></code></pre></div></li></ol><h3 id=option-3-docker-deployment-without-docker-compose>Option 3: Docker Deployment (Without Docker Compose)</h3><ol><li><p><strong>Build the Docker Image:</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>docker build -t subtitle-generator .
</span></span></code></pre></div></li><li><p><strong>Run the Docker Container:</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>docker run -d -p 8080:8080 --name subtitle-generator -e HF_AUTH_TOKEN<span style=color:#f92672>=</span>&lt;your_huggingface_token&gt; subtitle-generator
</span></span></code></pre></div><p>Replace <code>&lt;your_huggingface_token></code> with your actual Hugging Face token.</p></li><li><p><strong>Access the Application:</strong> Open your web browser and go to:</p><ul><li><code>http://localhost:8080</code> (if you&rsquo;re accessing it from the same machine)</li><li><code>http://&lt;your_server_ip>:8080</code> (if accessing from another device on your network, replace <code>&lt;your_server_ip></code> with the server&rsquo;s IP address)</li></ul><p>You should see the &ldquo;Subtitle Generator&rdquo; web page.</p></li></ol><h2 id=api-documentation>API Documentation</h2><p>The API provides a single endpoint for uploading audio files and receiving generated subtitles.</p><ul><li><strong>Endpoint:</strong> <code>/upload-audio/</code></li><li><strong>Method:</strong> <code>POST</code></li><li><strong>Request:</strong><ul><li><code>Content-Type</code>: <code>multipart/form-data</code></li><li><strong>Form Fields:</strong><ul><li><code>audio_file</code>: (Required) The audio file to be transcribed.</li><li><code>file_type</code>: (Required) The desired subtitle format: <code>srt</code> or <code>vtt</code>.</li></ul></li></ul></li><li><strong>Response:</strong><ul><li><strong>Success (Status Code: 200 OK):</strong><ul><li><code>Content-Type</code>: <code>application/x-subrip</code> (for <code>.srt</code>) or <code>text/vtt</code> (for <code>.vtt</code>).</li><li>The response body contains the generated subtitle file content, ready for download. The response headers include <code>Content-Disposition: attachment; filename="&lt;original_filename>.&lt;srt|vtt>"</code>, prompting the browser to download the file.</li></ul></li><li><strong>Error (Status Codes: 400, 413, 500):</strong><ul><li><code>Content-Type</code>: <code>application/json</code></li><li>Body: A JSON object containing an error description:<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>    <span style=color:#f92672>&#34;detail&#34;</span>: <span style=color:#e6db74>&#34;Error message describing the problem.&#34;</span>
</span></span><span style=display:flex><span>}
</span></span></code></pre></div></li><li><strong>Possible Error Scenarios:</strong><ul><li><strong>Unsupported File Format (400):</strong> If the uploaded file is not one of the supported formats (<code>.wav</code>, <code>.mp3</code>, <code>.m4a</code>, <code>.flac</code>). Example:<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{ <span style=color:#f92672>&#34;detail&#34;</span>: <span style=color:#e6db74>&#34;File format not supported. Please upload a file with one of the following extensions: .wav, .mp3, .m4a, .flac&#34;</span> }
</span></span></code></pre></div></li><li><strong>File Size Exceeded (413):</strong><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{ <span style=color:#f92672>&#34;detail&#34;</span>: <span style=color:#e6db74>&#34;File size exceeds the maximum limit of 50 MB.&#34;</span> }
</span></span></code></pre></div></li><li><strong>Processing Error (500):</strong> Any other error during transcription or diarization. The error message will provide more details. Example:<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{ <span style=color:#f92672>&#34;detail&#34;</span>: <span style=color:#e6db74>&#34;An unexpected error occurred during processing: &lt;specific error message&gt;&#34;</span> }
</span></span></code></pre></div></li><li><strong>Diarization/Token Error (500):</strong> If the Hugging Face token is invalid or missing, or if the user agreements haven&rsquo;t been accepted.<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{ <span style=color:#f92672>&#34;detail&#34;</span>: <span style=color:#e6db74>&#34;Failed to load diarization pipeline: ... Ensure your token has the necessary permissions and you have accepted the user conditions at [https://hf.co/pyannote/speaker-diarization](https://hf.co/pyannote/speaker-diarization).&#34;</span>}
</span></span></code></pre></div></li></ul></li></ul></li></ul></li></ul><h2 id=model-selection-and-hardware-considerations>Model Selection and Hardware Considerations</h2><p>The application automatically selects the most appropriate Whisper model based on your system&rsquo;s available RAM and VRAM (GPU memory). Here&rsquo;s how it works:</p><ol><li><strong>RAM Check:</strong> The script checks the total available system RAM.</li><li><strong>Model Prioritization:</strong> It then tries to load the largest possible Whisper model that fits within the available RAM, in this order of priority (largest/most accurate to smallest/fastest):<ul><li><code>large</code> (~10GB RAM required)</li><li><code>turbo</code> (~6GB RAM required)</li><li><code>medium</code> (~5GB RAM required)</li><li><code>small</code> (~2GB RAM required)</li><li><code>base</code> (~1GB RAM required)</li><li><code>tiny</code> (~1GB RAM required)</li></ul></li><li><strong>GPU (CUDA) Utilization:</strong> If a CUDA-enabled GPU is detected <em>and</em> its VRAM is sufficient for the selected model, the model will be loaded onto the GPU for significantly faster processing. Otherwise, it will use the CPU.</li><li>Insufficient RAM message: If your system has insufficient RAM the program raises an error and stops.</li></ol><p>This dynamic selection ensures optimal performance without requiring manual configuration. You&rsquo;ll see a message in the console indicating which model was selected and whether it&rsquo;s using the CPU or GPU.</p><h2 id=contributing>Contributing</h2><p>Contributions are welcome! If you&rsquo;d like to contribute:</p><ol><li>Fork the repository.</li><li>Create a new branch for your feature or bug fix: <code>git checkout -b feature/my-new-feature</code> or <code>git checkout -b bugfix/fix-issue-123</code>.</li><li>Make your changes and commit them with clear, concise commit messages.</li><li>Push your branch to your forked repository.</li><li>Submit a pull request to the main repository.</li></ol><h2 id=limitations>Limitations</h2><ul><li><strong>Model Accuracy:</strong> The accuracy of the subtitles depends on the selected Whisper model. Larger models are generally more accurate but require more resources. Noisy audio or complex language can also impact accuracy.</li><li><strong>Speaker Diarization:</strong> While pyannote.audio provides speaker diarization, it&rsquo;s not perfect. Overlapping speech or similar-sounding voices can sometimes lead to errors in speaker identification.</li></ul><h2 id=further-improvements-todos>Further Improvements (TODOs)</h2><ul><li><strong>Implement Progress Bar:</strong> Display a progress bar during upload and processing to provide feedback to the user.</li><li><strong>Improve Subtitle Quality:</strong> Explore techniques for improving subtitle segmentation and formatting (e.g., sentence-level segmentation, handling overlapping speech).</li><li><strong>Allow users to specify the model:</strong> Add a form field in the HTML page to let the user select the desired Whisper model (tiny, base, small, medium, large), overriding the automatic selection.</li><li><strong>Add a reset button:</strong> Add a button to reset the form.</li><li><strong>Add WebVTT styling capabilities:</strong> Research the WebVTT format and add options to specify parameters like text color and position.</li></ul><h3 id=view-code-on-i-classfab-fa-githubigithubhttpsgithubcomdgsi-upcsubtitle-generator><a href=https://github.com/DGSI-UPC/Subtitle-Generator>View Code on <i class="fab fa-github"></i>Github</a></h3></div><div class=post-footer><div class=post-navigation><a href=/posts/education/minichef-ar/ class=prev-post><i class="fas fa-arrow-left"></i>
<span><small>Previous</small>
<strong>MiniChef AR</strong>
</span></a><a href=/posts/education/web-to-markdown/ class=next-post><span><small>Next</small>
<strong>Web to Markdown</strong>
</span><i class="fas fa-arrow-right"></i></a></div><a href=/posts class=back-to-posts><i class="fas fa-th-list"></i> Back to all posts</a></div></article></div><footer class=footer><div class=footer-contact><a href=bernat.borrasc@gmail.com class=footer-link title=Email><i class="fas fa-envelope"></i>
</a><a href=https://github.com/bernatbc class=footer-link title=Github><i class="fab fa-github"></i>
</a><a href=https://www.youtube.com/channel/UCWuKGhwo6zB_ptObwrumZXw class=footer-link title=Youtube><i class="fa-brands fa-youtube"></i>
</a><a href=https://www.linkedin.com/in/bernat-borr%c3%a0s-i-civil/ class=footer-link title=LinkedIn><i class="fab fa-linkedin"></i>
</a><a href=https://devpost.com/bernat-borras-civil class=footer-link title=Devpost><i class="fa-solid fa-d"></i></a></div><div class=footer-copyright><p>© 2025 Copyright.</p><p>Powered by <a href=https://gohugo.io target=_blank>gohugo</a></p></div></footer></div></div></div><script>document.addEventListener("DOMContentLoaded",function(){const s=document.getElementById("navbar-toggle"),o=document.getElementById("navbar-nav");s.addEventListener("click",function(){o.classList.toggle("show")}),document.querySelectorAll("pre > code").forEach(function(e){const t=document.createElement("button");t.className="copy-code-button",t.type="button",t.innerHTML='<i class="fas fa-copy"></i> Copy';const s=e.parentNode,n=document.createElement("div");n.className="code-block-wrapper";const o=e.className;if(o&&o.startsWith("language-")){const e=o.replace("language-","");n.setAttribute("data-lang",e)}s.parentNode.insertBefore(n,s),n.appendChild(s),n.appendChild(t),t.addEventListener("click",function(){navigator.clipboard.writeText(e.textContent).then(function(){t.innerHTML='<i class="fas fa-check"></i> Copied!',setTimeout(function(){t.innerHTML='<i class="fas fa-copy"></i> Copy'},2e3)},function(){t.innerHTML='<i class="fas fa-times"></i> Error',setTimeout(function(){t.innerHTML='<i class="fas fa-copy"></i> Copy'},2e3)})})});const e=document.querySelector(".post-content"),t=document.getElementById("toc-content");if(e&&t){const n=e.querySelectorAll("h2, h3, h4");if(n.length>0){const e=document.createElement("ul");n.forEach((t,n)=>{t.id||(t.id="heading-"+n);const o=document.createElement("li");o.className="toc-"+t.tagName.toLowerCase();const s=document.createElement("a");s.href="#"+t.id,s.textContent=t.textContent,o.appendChild(s),e.appendChild(o),s.addEventListener("click",function(e){e.preventDefault(),document.getElementById(t.id).scrollIntoView({behavior:"smooth"}),history.pushState(null,null,"#"+t.id)})}),t.appendChild(e)}else document.querySelector(".toc-container").style.display="none"}const n=document.querySelectorAll(".toc-content a");n.length&&window.addEventListener("scroll",function(){let e=null;const t=window.scrollY;document.querySelectorAll(".post-content h1, .post-content h2, .post-content h3, .post-content h4").forEach(n=>{const s=n.offsetTop;s-100<=t&&(e=document.querySelector(`.toc-content a[href="#${n.id}"]`))}),n.forEach(e=>{e.classList.remove("active")}),e&&e.classList.add("active")})})</script></body></html>