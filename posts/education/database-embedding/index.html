<!doctype html><html lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Database Embedding - BernatBC</title>
<link rel=stylesheet href=https://bernatbc.tk/styles/style.min.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/katex.min.css integrity=sha384-zh0CIslj+VczCZtlzBcjt5ppRcsAmDnRem7ESsYwWwg3m/OaJ2l4x7YBZl9Kxxib crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/katex.min.js integrity=sha384-Rma6DA2IPUwhNxmrB/7S3Tno0YY7sFu9WSYMCuulLhIqYSGZ2gKCJWIqhBWqMQfh crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/contrib/auto-render.min.js integrity=sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh crossorigin=anonymous onload=renderMathInElement(document.body)></script></head><body class=dark-theme><div class=page-wrapper><nav class=navbar><div class=navbar-container><button id=navbar-toggle class=navbar-toggle>
<i class="fas fa-bars"></i></button><div class=navbar-nav id=navbar-nav><ul><li><a href=/#profile class=nav-link><i class="fas fa-user"></i> Profile</a></li><li><a href=/#skills class=nav-link><i class="fas fa-code"></i> Skills</a></li><li><a href=/#experiences class=nav-link><i class="fas fa-briefcase"></i> Experiences</a></li><li><a href=/#education class=nav-link><i class="fas fa-graduation-cap"></i> Education</a></li><li><a href=/#projects class=nav-link><i class="fas fa-project-diagram"></i> Open Source Projects</a></li><li><a href=/#recent-posts class=nav-link><i class="fas fa-newspaper"></i> Recent Posts</a></li><li><a href=/posts class="nav-link active"><i class="fas fa-pen"></i> All Posts</a></li></ul></div></div></nav><div class=content-wrapper><aside class=toc-container><div class=toc><h3 class=toc-title><i class="fas fa-list"></i> Table of Contents</h3><div id=toc-content class=toc-content></div></div></aside><div class=main-content><div class=container><article class=post-single><header class=post-header><h1 class=section-title>Database Embedding</h1><div class=post-meta><div class=post-meta-top><span class=post-date><i class="far fa-calendar-alt"></i> March 6, 2025</span></div><div class=post-tags><span class=post-tag>AI</span>
<span class=post-tag>Education</span>
<span class=post-tag>Mini-hackathon</span>
<span class=post-tag>Python</span></div></div><div class=post-featured-image><img src=/posts/education/database-embedding/hero.png alt="Database Embedding"></div></header><div class=post-content><h1 id=markdown-to-chromadb-indexer>Markdown to ChromaDB Indexer</h1><p>This tool indexes markdown files into ChromaDB for efficient semantic search capabilities, with support for both default embeddings and OpenAI&rsquo;s text-embedding-3-small model for enhanced search quality.</p><h2 id=features>Features</h2><ul><li>Flexible embedding options:<ul><li>Default ChromaDB embeddings (no API key required)</li><li>Optional OpenAI text-embedding-3-small model for enhanced quality</li></ul></li><li>Recursively processes markdown files in a directory</li><li>Intelligent text chunking with configurable size and overlap</li><li>Sentence-aware splitting to maintain context</li><li>Extracts and preserves frontmatter metadata</li><li>Converts markdown to searchable text</li><li>Stores documents with their metadata in ChromaDB</li><li>Supports semantic search queries</li><li>Batch processing for large datasets</li></ul><h2 id=installation>Installation</h2><ol><li>Install the required dependencies:</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>pip install -r requirements.txt
</span></span></code></pre></div><ol start=2><li>(Optional) Set up OpenAI embeddings:<ul><li>Create a <code>.env</code> file with your OpenAI API key:</li></ul></li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>OPENAI_API_KEY<span style=color:#f92672>=</span>your_api_key_here
</span></span></code></pre></div><h2 id=usage>Usage</h2><p>To index your markdown files:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>python index_markdown.py index /path/to/your/markdown/directory
</span></span></code></pre></div><p>Optional arguments:</p><ul><li><code>--db-path</code>: Specify a custom path for ChromaDB persistence (default: &ldquo;chroma_db&rdquo;)</li><li><code>--chunk-size</code>: Maximum number of characters per chunk (default: 500)</li><li><code>--chunk-overlap</code>: Number of characters to overlap between chunks (default: 50)</li><li><code>--use-openai</code>: Use OpenAI embeddings instead of default embeddings (requires API key)</li></ul><h3 id=examples>Examples</h3><p>Index with custom settings:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># Using default embeddings</span>
</span></span><span style=display:flex><span>python index_markdown.py index /path/to/markdown --chunk-size <span style=color:#ae81ff>1000</span> --chunk-overlap <span style=color:#ae81ff>100</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Using OpenAI embeddings (requires API key)</span>
</span></span><span style=display:flex><span>python index_markdown.py index /path/to/markdown --use-openai
</span></span></code></pre></div><h2 id=python-api-usage>Python API Usage</h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> index_markdown <span style=color:#f92672>import</span> MarkdownIndexer
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Initialize the indexer with custom settings</span>
</span></span><span style=display:flex><span>indexer <span style=color:#f92672>=</span> MarkdownIndexer(
</span></span><span style=display:flex><span>    persist_dir<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;chroma_db&#34;</span>,
</span></span><span style=display:flex><span>    chunk_size<span style=color:#f92672>=</span><span style=color:#ae81ff>500</span>,  <span style=color:#75715e># characters per chunk</span>
</span></span><span style=display:flex><span>    chunk_overlap<span style=color:#f92672>=</span><span style=color:#ae81ff>50</span>,  <span style=color:#75715e># overlap between chunks</span>
</span></span><span style=display:flex><span>    use_openai<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>  <span style=color:#75715e># set to True to use OpenAI embeddings</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Index a directory of markdown files</span>
</span></span><span style=display:flex><span>indexer<span style=color:#f92672>.</span>index_directory(<span style=color:#e6db74>&#34;/path/to/markdown/files&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Query the indexed documents</span>
</span></span><span style=display:flex><span>results <span style=color:#f92672>=</span> indexer<span style=color:#f92672>.</span>query_documents(<span style=color:#e6db74>&#34;your search query&#34;</span>, n_results<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>)
</span></span></code></pre></div><h2 id=text-chunking>Text Chunking</h2><p>The indexer uses an intelligent chunking strategy:</p><ol><li><strong>Sentence-Aware Splitting</strong>: Text is split at sentence boundaries to maintain context</li><li><strong>Configurable Chunk Size</strong>: Control the size of each chunk (default: 500 characters)</li><li><strong>Overlap Between Chunks</strong>: Maintains context between chunks (default: 50 characters)</li><li><strong>Metadata Preservation</strong>: Each chunk maintains:<ul><li>Original document metadata</li><li>Chunk index</li><li>Total chunks in document</li><li>Source file path</li></ul></li></ol><h2 id=batch-processing>Batch Processing</h2><p>Documents are processed in batches (100 chunks per batch) to efficiently handle large datasets and manage memory usage.</p><h2 id=notes>Notes</h2><ul><li>Processes all files with <code>.md</code> or <code>.markdown</code> extensions</li><li>Each chunk is stored with complete metadata for traceability</li><li>Uses BeautifulSoup for robust HTML parsing</li><li>ChromaDB persistence directory is created if it doesn&rsquo;t exist</li><li>Unique IDs are generated for each chunk (format: <code>filename_chunk_N</code>)</li></ul><h2 id=querying-the-index>Querying the Index</h2><h3 id=using-command-line>Using Command Line</h3><p>The script provides a simple command-line interface for searching:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># Basic search</span>
</span></span><span style=display:flex><span>python index_markdown.py query <span style=color:#e6db74>&#34;your search query&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Search with more results</span>
</span></span><span style=display:flex><span>python index_markdown.py query <span style=color:#e6db74>&#34;your search query&#34;</span> --n-results <span style=color:#ae81ff>10</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Search using OpenAI embeddings</span>
</span></span><span style=display:flex><span>python index_markdown.py query <span style=color:#e6db74>&#34;your search query&#34;</span> --use-openai
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Filter results by file path</span>
</span></span><span style=display:flex><span>python index_markdown.py query <span style=color:#e6db74>&#34;your search query&#34;</span> --path-filter <span style=color:#e6db74>&#34;docs/&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Specify different database path</span>
</span></span><span style=display:flex><span>python index_markdown.py query <span style=color:#e6db74>&#34;your search query&#34;</span> --db-path <span style=color:#e6db74>&#34;custom_db&#34;</span>
</span></span></code></pre></div><h3 id=using-python>Using Python</h3><p>You can query the indexed documents in two ways:</p><ol><li>Using the existing indexer:</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> index_markdown <span style=color:#f92672>import</span> MarkdownIndexer
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Initialize with the same settings used for indexing</span>
</span></span><span style=display:flex><span>indexer <span style=color:#f92672>=</span> MarkdownIndexer(
</span></span><span style=display:flex><span>    persist_dir<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;chroma_db&#34;</span>,  <span style=color:#75715e># use the same directory as indexing</span>
</span></span><span style=display:flex><span>    use_openai<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>  <span style=color:#75715e># set to True if you used OpenAI embeddings for indexing</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Simple query</span>
</span></span><span style=display:flex><span>results <span style=color:#f92672>=</span> indexer<span style=color:#f92672>.</span>query_documents(
</span></span><span style=display:flex><span>    query_text<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;your search query here&#34;</span>,
</span></span><span style=display:flex><span>    n_results<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>  <span style=color:#75715e># number of results to return</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Process results</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> i, (document, metadata, score) <span style=color:#f92672>in</span> enumerate(zip(
</span></span><span style=display:flex><span>    results[<span style=color:#e6db74>&#39;documents&#39;</span>][<span style=color:#ae81ff>0</span>],
</span></span><span style=display:flex><span>    results[<span style=color:#e6db74>&#39;metadatas&#39;</span>][<span style=color:#ae81ff>0</span>],
</span></span><span style=display:flex><span>    results[<span style=color:#e6db74>&#39;distances&#39;</span>][<span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>)):
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>Result </span><span style=color:#e6db74>{</span>i<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span><span style=color:#e6db74>}</span><span style=color:#e6db74> (similarity: </span><span style=color:#e6db74>{</span><span style=color:#ae81ff>1</span><span style=color:#f92672>-</span>score<span style=color:#e6db74>:</span><span style=color:#e6db74>.3f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>)&#34;</span>)
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Source: </span><span style=color:#e6db74>{</span>metadata[<span style=color:#e6db74>&#39;source_path&#39;</span>]<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Chunk: </span><span style=color:#e6db74>{</span>metadata[<span style=color:#e6db74>&#39;chunk_index&#39;</span>]<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span><span style=color:#e6db74>}</span><span style=color:#e6db74>/</span><span style=color:#e6db74>{</span>metadata[<span style=color:#e6db74>&#39;total_chunks&#39;</span>]<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;Content:&#34;</span>, document)
</span></span></code></pre></div><ol start=2><li>Using ChromaDB directly:</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> chromadb
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> chromadb.utils <span style=color:#f92672>import</span> embedding_functions
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Initialize the client</span>
</span></span><span style=display:flex><span>client <span style=color:#f92672>=</span> chromadb<span style=color:#f92672>.</span>PersistentClient(path<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;chroma_db&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Get the collection</span>
</span></span><span style=display:flex><span>collection <span style=color:#f92672>=</span> client<span style=color:#f92672>.</span>get_collection(
</span></span><span style=display:flex><span>    name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;markdown_docs&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#75715e># Use the same embedding function as during indexing</span>
</span></span><span style=display:flex><span>    embedding_function<span style=color:#f92672>=</span>embedding_functions<span style=color:#f92672>.</span>SentenceTransformerEmbeddingFunction()
</span></span><span style=display:flex><span>    <span style=color:#75715e># Or for OpenAI:</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># embedding_function=embedding_functions.OpenAIEmbeddingFunction(</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>#     api_key=&#34;your_key&#34;,</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>#     model_name=&#34;text-embedding-3-small&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># )</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Query with filters</span>
</span></span><span style=display:flex><span>results <span style=color:#f92672>=</span> collection<span style=color:#f92672>.</span>query(
</span></span><span style=display:flex><span>    query_texts<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;your search query&#34;</span>],
</span></span><span style=display:flex><span>    n_results<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>,
</span></span><span style=display:flex><span>    <span style=color:#75715e># Optional: filter by metadata</span>
</span></span><span style=display:flex><span>    where<span style=color:#f92672>=</span>{<span style=color:#e6db74>&#34;source_path&#34;</span>: {<span style=color:#e6db74>&#34;$contains&#34;</span>: <span style=color:#e6db74>&#34;specific/path&#34;</span>}},
</span></span><span style=display:flex><span>    <span style=color:#75715e># Optional: include relevance score</span>
</span></span><span style=display:flex><span>    include<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;metadatas&#34;</span>, <span style=color:#e6db74>&#34;documents&#34;</span>, <span style=color:#e6db74>&#34;distances&#34;</span>]
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><h3 id=advanced-query-features>Advanced Query Features</h3><ol><li><strong>Metadata Filtering</strong>: Filter results based on metadata fields:</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Filter by specific file path</span>
</span></span><span style=display:flex><span>results <span style=color:#f92672>=</span> collection<span style=color:#f92672>.</span>query(
</span></span><span style=display:flex><span>    query_texts<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;query&#34;</span>],
</span></span><span style=display:flex><span>    where<span style=color:#f92672>=</span>{<span style=color:#e6db74>&#34;source_path&#34;</span>: {<span style=color:#e6db74>&#34;$contains&#34;</span>: <span style=color:#e6db74>&#34;docs/&#34;</span>}}
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Filter by chunk index</span>
</span></span><span style=display:flex><span>results <span style=color:#f92672>=</span> collection<span style=color:#f92672>.</span>query(
</span></span><span style=display:flex><span>    query_texts<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;query&#34;</span>],
</span></span><span style=display:flex><span>    where<span style=color:#f92672>=</span>{<span style=color:#e6db74>&#34;chunk_index&#34;</span>: {<span style=color:#e6db74>&#34;$lt&#34;</span>: <span style=color:#ae81ff>3</span>}}  <span style=color:#75715e># only first 3 chunks</span>
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><ol start=2><li><strong>Batch Queries</strong>: Search multiple queries at once:</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>results <span style=color:#f92672>=</span> collection<span style=color:#f92672>.</span>query(
</span></span><span style=display:flex><span>    query_texts<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;query1&#34;</span>, <span style=color:#e6db74>&#34;query2&#34;</span>, <span style=color:#e6db74>&#34;query3&#34;</span>],
</span></span><span style=display:flex><span>    n_results<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><h3 id=query-results>Query Results</h3><p>Results include:</p><ul><li><strong>Document Content</strong>: The text chunk that matches your query</li><li><strong>Metadata</strong>:<ul><li><code>source_path</code>: Original markdown file path</li><li><code>chunk_index</code>: Position of the chunk in the document</li><li><code>total_chunks</code>: Total number of chunks in the document</li><li>Any frontmatter metadata from the original markdown</li></ul></li><li><strong>Distance Score</strong>: Lower scores indicate better matches (using cosine similarity)</li></ul><p>Results are ordered by semantic similarity to the query, with the most relevant chunks appearing first.</p><h3 id=view-code-on-i-classfab-fa-githubigithubhttpsgithubcomdgsi-upcchromadb-embedding><a href=https://github.com/DGSI-UPC/ChromaDB-Embedding/>View Code on <i class="fab fa-github"></i>Github</a></h3></div><div class=post-footer><div class=post-navigation><a href=/posts/education/web-to-markdown/ class=prev-post><i class="fas fa-arrow-left"></i>
<span><small>Previous</small>
<strong>Web to Markdown</strong>
</span></a><a href=/posts/education/llm-chat-rag/ class=next-post><span><small>Next</small>
<strong>LLM Chat RAG</strong>
</span><i class="fas fa-arrow-right"></i></a></div><a href=/posts class=back-to-posts><i class="fas fa-th-list"></i> Back to all posts</a></div></article></div><footer class=footer><div class=footer-contact><a href=bernat.borrasc@gmail.com class=footer-link title=Email><i class="fas fa-envelope"></i>
</a><a href=https://github.com/bernatbc class=footer-link title=Github><i class="fab fa-github"></i>
</a><a href=https://www.youtube.com/channel/UCWuKGhwo6zB_ptObwrumZXw class=footer-link title=Youtube><i class="fa-brands fa-youtube"></i>
</a><a href=https://www.linkedin.com/in/bernat-borr%c3%a0s-i-civil/ class=footer-link title=LinkedIn><i class="fab fa-linkedin"></i>
</a><a href=https://devpost.com/bernat-borras-civil class=footer-link title=Devpost><i class="fa-solid fa-d"></i></a></div><div class=footer-copyright><p>© 2025 Copyright.</p><p>Powered by <a href=https://gohugo.io target=_blank>gohugo</a></p></div></footer></div></div></div><script>document.addEventListener("DOMContentLoaded",function(){const s=document.getElementById("navbar-toggle"),o=document.getElementById("navbar-nav");s.addEventListener("click",function(){o.classList.toggle("show")}),document.querySelectorAll("pre > code").forEach(function(e){const t=document.createElement("button");t.className="copy-code-button",t.type="button",t.innerHTML='<i class="fas fa-copy"></i> Copy';const s=e.parentNode,n=document.createElement("div");n.className="code-block-wrapper";const o=e.className;if(o&&o.startsWith("language-")){const e=o.replace("language-","");n.setAttribute("data-lang",e)}s.parentNode.insertBefore(n,s),n.appendChild(s),n.appendChild(t),t.addEventListener("click",function(){navigator.clipboard.writeText(e.textContent).then(function(){t.innerHTML='<i class="fas fa-check"></i> Copied!',setTimeout(function(){t.innerHTML='<i class="fas fa-copy"></i> Copy'},2e3)},function(){t.innerHTML='<i class="fas fa-times"></i> Error',setTimeout(function(){t.innerHTML='<i class="fas fa-copy"></i> Copy'},2e3)})})});const e=document.querySelector(".post-content"),t=document.getElementById("toc-content");if(e&&t){const n=e.querySelectorAll("h2, h3, h4");if(n.length>0){const e=document.createElement("ul");n.forEach((t,n)=>{t.id||(t.id="heading-"+n);const o=document.createElement("li");o.className="toc-"+t.tagName.toLowerCase();const s=document.createElement("a");s.href="#"+t.id,s.textContent=t.textContent,o.appendChild(s),e.appendChild(o),s.addEventListener("click",function(e){e.preventDefault(),document.getElementById(t.id).scrollIntoView({behavior:"smooth"}),history.pushState(null,null,"#"+t.id)})}),t.appendChild(e)}else document.querySelector(".toc-container").style.display="none"}const n=document.querySelectorAll(".toc-content a");n.length&&window.addEventListener("scroll",function(){let e=null;const t=window.scrollY;document.querySelectorAll(".post-content h1, .post-content h2, .post-content h3, .post-content h4").forEach(n=>{const s=n.offsetTop;s-100<=t&&(e=document.querySelector(`.toc-content a[href="#${n.id}"]`))}),n.forEach(e=>{e.classList.remove("active")}),e&&e.classList.add("active")})})</script></body></html>