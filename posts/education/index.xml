<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Education on BernatBC</title><link>https://bernatbc.tk/posts/education/</link><description>Recent content in Education on BernatBC</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Thu, 13 Mar 2025 06:00:23 +0600</lastBuildDate><atom:link href="https://bernatbc.tk/posts/education/index.xml" rel="self" type="application/rss+xml"/><item><title>LLM Chat RAG</title><link>https://bernatbc.tk/posts/education/llm-chat-rag/</link><pubDate>Thu, 13 Mar 2025 06:00:23 +0600</pubDate><guid>https://bernatbc.tk/posts/education/llm-chat-rag/</guid><description>&lt;h1 id="llm-chat-rag---cli-interface">LLM Chat RAG - CLI Interface&lt;/h1>
&lt;h2 id="overview">Overview&lt;/h2>
&lt;p>The &lt;strong>LLM Chat RAG&lt;/strong> (Retriever-Augmented Generation) is a Command Line Interface (CLI) tool that allows you to interact with documents stored in a ChromaDB database using OpenAI&amp;rsquo;s GPT-4o-mini model. This system provides a way to query documents for relevant information, retrieve context, and generate AI-driven responses based on that context.&lt;/p>
&lt;h2 id="features">Features&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Retriever-Augmented Generation (RAG):&lt;/strong> Retrieve context from a database and use it to generate more accurate and informative responses.&lt;/li>
&lt;li>&lt;strong>OpenAI GPT-4o-mini Model:&lt;/strong> Uses OpenAI&amp;rsquo;s GPT-4o-mini to generate answers based on the retrieved context.&lt;/li>
&lt;li>&lt;strong>ChromaDB Integration:&lt;/strong> Uses ChromaDB for efficient document retrieval and context management.&lt;/li>
&lt;li>&lt;strong>Command-line interface:&lt;/strong> Interact with the system through an intuitive CLI, allowing commands such as &lt;code>/help&lt;/code>, &lt;code>/exit&lt;/code>, and &lt;code>/sources&lt;/code>.&lt;/li>
&lt;/ul>
&lt;h2 id="prerequisites">Prerequisites&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Python 3.x&lt;/strong>: Ensure Python 3.6 or later is installed.&lt;/li>
&lt;li>&lt;strong>OpenAI API Key&lt;/strong>: You must have an OpenAI API key to use the GPT model.&lt;/li>
&lt;li>&lt;strong>ChromaDB&lt;/strong>: A local or cloud-based ChromaDB instance for document storage and retrieval.&lt;/li>
&lt;/ul>
&lt;h2 id="setup">Setup&lt;/h2>
&lt;h3 id="1-install-dependencies">1. Install Dependencies&lt;/h3>
&lt;p>Install required dependencies via &lt;code>pip&lt;/code>:&lt;/p></description></item><item><title>Database Embedding</title><link>https://bernatbc.tk/posts/education/database-embedding/</link><pubDate>Thu, 06 Mar 2025 06:00:23 +0600</pubDate><guid>https://bernatbc.tk/posts/education/database-embedding/</guid><description>&lt;h1 id="markdown-to-chromadb-indexer">Markdown to ChromaDB Indexer&lt;/h1>
&lt;p>This tool indexes markdown files into ChromaDB for efficient semantic search capabilities, with support for both default embeddings and OpenAI&amp;rsquo;s text-embedding-3-small model for enhanced search quality.&lt;/p>
&lt;h2 id="features">Features&lt;/h2>
&lt;ul>
&lt;li>Flexible embedding options:
&lt;ul>
&lt;li>Default ChromaDB embeddings (no API key required)&lt;/li>
&lt;li>Optional OpenAI text-embedding-3-small model for enhanced quality&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Recursively processes markdown files in a directory&lt;/li>
&lt;li>Intelligent text chunking with configurable size and overlap&lt;/li>
&lt;li>Sentence-aware splitting to maintain context&lt;/li>
&lt;li>Extracts and preserves frontmatter metadata&lt;/li>
&lt;li>Converts markdown to searchable text&lt;/li>
&lt;li>Stores documents with their metadata in ChromaDB&lt;/li>
&lt;li>Supports semantic search queries&lt;/li>
&lt;li>Batch processing for large datasets&lt;/li>
&lt;/ul>
&lt;h2 id="installation">Installation&lt;/h2>
&lt;ol>
&lt;li>Install the required dependencies:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>pip install -r requirements.txt
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="2">
&lt;li>(Optional) Set up OpenAI embeddings:
&lt;ul>
&lt;li>Create a &lt;code>.env&lt;/code> file with your OpenAI API key:&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>OPENAI_API_KEY&lt;span style="color:#f92672">=&lt;/span>your_api_key_here
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="usage">Usage&lt;/h2>
&lt;p>To index your markdown files:&lt;/p></description></item><item><title>Web to Markdown</title><link>https://bernatbc.tk/posts/education/web-to-markdown/</link><pubDate>Thu, 27 Feb 2025 06:00:23 +0600</pubDate><guid>https://bernatbc.tk/posts/education/web-to-markdown/</guid><description>&lt;h1 id="web-to-markdown">Web-to-Markdown&lt;/h1>
&lt;p>The purpose of this project is to be able to convert the information from any website into a Markdown bucket.&lt;/p>
&lt;h2 id="usage">Usage&lt;/h2>
&lt;p>This website has a UI with a text field in the middle. Enter the base URL of the website you want to extract information from and it will automatically find all the attached links to it and also extract information from them.&lt;/p>
&lt;p>To extract this information we get the HTML using the library trafilatura and parse it using BeautifulSoup and html2text.&lt;/p></description></item><item><title>Subtitle Generator</title><link>https://bernatbc.tk/posts/education/subtitle-generator/</link><pubDate>Thu, 20 Feb 2025 06:00:23 +0600</pubDate><guid>https://bernatbc.tk/posts/education/subtitle-generator/</guid><description>&lt;h1 id="subtitle-generator">Subtitle Generator&lt;/h1>





&lt;div class="video-container">
 &lt;video class="video-player" id="video-1764168265162705695" playsinline controls>
 &lt;source src="subtitle_generator.mp4" type="video/mp4" />
 &lt;/video>
&lt;/div>
&lt;p>This project provides a web application that automatically generates subtitles (in SRT or VTT format) from audio files. It leverages the power of OpenAI&amp;rsquo;s Whisper speech recognition model for transcription and pyannote.audio for speaker diarization, all wrapped in a user-friendly FastAPI web interface.&lt;/p>
&lt;h2 id="features">Features&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Web Interface:&lt;/strong> A clean, simple HTML interface for uploading audio files. No complex command-line usage is required.&lt;/li>
&lt;li>&lt;strong>Multiple Audio Formats:&lt;/strong> Supports &lt;code>.wav&lt;/code>, &lt;code>.mp3&lt;/code>, &lt;code>.m4a&lt;/code>, and &lt;code>.flac&lt;/code> files. Automatic conversion to WAV is handled internally.&lt;/li>
&lt;li>&lt;strong>Speaker Diarization:&lt;/strong> Identifies different speakers in the audio and includes speaker labels in the generated subtitles.&lt;/li>
&lt;li>&lt;strong>Subtitle Formats:&lt;/strong> Generates subtitles in either &lt;code>.srt&lt;/code> (SubRip) or &lt;code>.vtt&lt;/code> (WebVTT) format, selectable via the web interface.&lt;/li>
&lt;li>&lt;strong>Fast and Efficient:&lt;/strong> Utilizes a dynamically selected Whisper model (from &lt;code>tiny&lt;/code> to &lt;code>large&lt;/code>) based on your system&amp;rsquo;s available RAM and VRAM (GPU memory), optimizing for performance and accuracy.&lt;/li>
&lt;li>&lt;strong>Easy Deployment:&lt;/strong> Can be run directly with Uvicorn or easily deployed using Docker and Docker Compose.&lt;/li>
&lt;li>&lt;strong>Well-Defined API:&lt;/strong> A single &lt;code>/upload-audio/&lt;/code> endpoint handles file uploads and subtitle generation, with clear request and response formats.&lt;/li>
&lt;li>&lt;strong>File Size Limit:&lt;/strong> The maximum upload file is limited to 50MB.&lt;/li>
&lt;/ul>
&lt;h2 id="requirements">Requirements&lt;/h2>
&lt;p>Before you get started, make sure you have the following:&lt;/p></description></item><item><title>MiniChef AR</title><link>https://bernatbc.tk/posts/education/minichef-ar/</link><pubDate>Thu, 19 Dec 2024 06:00:23 +0600</pubDate><guid>https://bernatbc.tk/posts/education/minichef-ar/</guid><description>&lt;h2 id="the-statement">The statement&lt;/h2>
&lt;p>We were asked to develop an Augmented Reality application using &lt;a href="https://unity.com/">Unity&lt;/a> and either &lt;a href="https://www.artoolkitx.org/">AR Toolkit&lt;/a>, &lt;a href="https://developer.vuforia.com/">Vuforia&lt;/a>, &lt;a href="https://www.easyar.com/">EasyAR&lt;/a> or &lt;a href="https://docs.unity3d.com/Packages/com.unity.xr.arfoundation@6.0/manual/index.html">ARFoundation&lt;/a>. The app needed to have the following features:&lt;/p>
&lt;ul>
&lt;li>Possibility of detection of more than one marker at the same time, or the use of more than one virtual object recorded in the real world.&lt;/li>
&lt;li>The user must be able to apply some geometric transformations to each of them virtual objects relative to their initial position (or marker). You can apply these geometric transformations, if you want, doing some animation with (or between) the virtual objects, as long as this animation has been programmed by you.&lt;/li>
&lt;li>Presence of an animated 3D character (humanoid) with which the user can interact somehow. This character must make sense within the context of the project.&lt;/li>
&lt;li>Offer the user some interaction mechanism (apart from the already included tracking), both with the virtual objects (directly or indirectly) as with application control.&lt;/li>
&lt;/ul>
&lt;h2 id="what-weve-made">What we&amp;rsquo;ve made&lt;/h2>
&lt;p>We&amp;rsquo;ve decided to go with &lt;a href="https://docs.unity3d.com/Packages/com.unity.xr.arfoundation@6.0/manual/index.html">ARFoundation&lt;/a> as it seemed to be the recommended one by &lt;a href="https://unity.com/">Unity&lt;/a>, as it was already preinstalled when selecting the AR template.
In the video below you can take a look at the resulting app. To sum it up, we&amp;rsquo;re tracking a Menu, where you can check the available dishes alongside its information. Afterwards, you can tell the chef to cook a certain dish, and a few seconds later, the dish will appear in a 3rd tracker.&lt;/p></description></item><item><title>VR Battlefield</title><link>https://bernatbc.tk/posts/education/vr-battlefield/</link><pubDate>Fri, 15 Nov 2024 06:00:23 +0600</pubDate><guid>https://bernatbc.tk/posts/education/vr-battlefield/</guid><description>&lt;h2 id="the-statement">The statement&lt;/h2>
&lt;p>We were asked to develop a Virtual Reality application using &lt;a href="https://unity.com/">Unity&lt;/a> and &lt;a href="https://arvr.google.com/cardboard/">Google Cardboard&lt;/a>. The app needed to have the following features:&lt;/p>
&lt;ul>
&lt;li>A virtual reality environment with various objects that can be interacted with.&lt;/li>
&lt;li>Navigation: you can use either the reticle pointer provided by GoogleVR or the data entry from the mobile phone&amp;rsquo;s accelerometer, to move the camera within the environment virtual. You can implement any of the metaphors that we have seen in the classes of theory (constant movement, plane route selection, teleportation, etc.)&lt;/li>
&lt;li>Selection: The user must have some 3DUI mode to be able to select objects from the scene, as well as being able to apply geometric transformations to perform tasks of manipulation (rotation, translation, scaling).&lt;/li>
&lt;li>Control: Offer the user the possibility of doing some control task via 3D GUIs, for example example: modify the color of some object, load a model into the scene, etc.&lt;/li>
&lt;/ul>
&lt;h2 id="what-weve-made">What we&amp;rsquo;ve made&lt;/h2>
&lt;p>In the video below you can take a look at the resulting app. To sum it up, we created a battleground environment where you can interact with several objects, such as grenades, mines and guns.&lt;/p></description></item><item><title>3D Image Viewer</title><link>https://bernatbc.tk/posts/education/3dimageviewer/</link><pubDate>Mon, 01 Jul 2024 06:00:23 +0600</pubDate><guid>https://bernatbc.tk/posts/education/3dimageviewer/</guid><description>&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>This project was made for my bachelor thesis. You can take a look the full report &lt;a href="https://upcommons.upc.edu/handle/2117/411671">here&lt;/a> (note that&amp;rsquo;s in catalan).&lt;/p>
&lt;h2 id="abstract">Abstract&lt;/h2>
&lt;p>Since the arrival of the photographic camera, humans have seen the need to find a way to organize photographs. Nowadays, the ease and simplicity of taking a photograph causes large quantities of them to accumulate. The most popular photo viewers and galleries display one image after another, in a list or grid, making it difficult to organize and searching them.&lt;/p></description></item><item><title>Object Tracker</title><link>https://bernatbc.tk/posts/education/objecttracker/</link><pubDate>Fri, 23 Jun 2023 06:00:23 +0600</pubDate><guid>https://bernatbc.tk/posts/education/objecttracker/</guid><description>&lt;h2 id="the-statement">The statement&lt;/h2>
&lt;p>&lt;a href="https://amoudgl.github.io/tlp/">Long-Term Visual Object Tracking Benchmark&lt;/a> is a dataset to benchmark object tracking algorithms. We were asked to implement four different algorithms. Two using tracking techniques, and two using recognition. For each technique, we had to implement one from scratch (an algorithm made for us) and another one extracted from the internet.&lt;/p>
&lt;p>Given a series of frames and a bounding box corresponding to the object to track, the algorithm should follow the object. To evaluate the precision, we used the overlapping ratio between the computed bounding box and the optimal bounding box (which was given via a txt file).&lt;/p></description></item><item><title>Î»-Calculus Telegram Bot</title><link>https://bernatbc.tk/posts/education/lambdacalculustelegrambot/</link><pubDate>Tue, 13 Jun 2023 06:00:23 +0600</pubDate><guid>https://bernatbc.tk/posts/education/lambdacalculustelegrambot/</guid><description>&lt;h2 id="the-statement">The statement&lt;/h2>
&lt;p>We were asked to make a lambda-calculus interpreter created by &lt;a href="https://en.wikipedia.org/wiki/Alonzo_Church">Alonzo Church&lt;/a>. This interpreter had also to support the definition and use of macros, a variable name for another expression. Those macros had to be evaluated in an infix (if it&amp;rsquo;s a symbol) or a prefix mode (otherwise). On top of that, our interpreter had to run in a &lt;a href="https://telegram.org/">Telegram&lt;/a> chat. Finally, we had to add the capability to print our expression as a tree in an image.&lt;/p></description></item><item><title>Document manager</title><link>https://bernatbc.tk/posts/education/documentmanager/</link><pubDate>Sun, 22 Jan 2023 06:00:23 +0600</pubDate><guid>https://bernatbc.tk/posts/education/documentmanager/</guid><description>&lt;h2 id="the-statement">The statement&lt;/h2>
&lt;p>The &lt;em>Programming Projects&lt;/em> college subject asked us to create an application to manage documents using Java. This application has to feature the creation of a document, importing and exporting files in three different formats: plaintext, XML and our own format. The application also has to have the ability to delete and modify these documents. The main feature of the application is the various document queries that allow us to find a certain document or author in the application.&lt;/p></description></item><item><title>Mars Planification</title><link>https://bernatbc.tk/posts/education/planification/</link><pubDate>Sat, 14 Jan 2023 06:00:23 +0600</pubDate><guid>https://bernatbc.tk/posts/education/planification/</guid><description>&lt;h2 id="the-statement">The statement&lt;/h2>
&lt;p>We are in the year 2075 and the first colonizers of Mars have established a network of bases throughout the geography of the planet that can be of two types, settlements (where the settlers live) and warehouses (where supplies arrive from the Earth). Moving between these bases is done by rovers that can move supplies and specialized personnel. It is not possible to always go directly from one base to another, we have a map (connected graph) that tells us which movements are possible.&lt;/p></description></item><item><title>Workout Planner</title><link>https://bernatbc.tk/posts/education/knowledgebasedsystems/</link><pubDate>Mon, 19 Dec 2022 06:00:23 +0600</pubDate><guid>https://bernatbc.tk/posts/education/knowledgebasedsystems/</guid><description>&lt;h2 id="the-statement">The statement&lt;/h2>
&lt;p>The progressive aging of the population is showing the importance of maintaining a set of healthy habits and promote physical exercise throughout life. When you reach a certain age it is necessary to have help to determine what types of exercises and activities are the most appropriate taking into account all factors that may affect the performance of those activities.&lt;/p>
&lt;p>Basically, we had to make a &lt;a href="https://clipsrules.net/">CLIPS&lt;/a> script that after given certain information about a person, we had to output an exercise planning suitable for him/her. We were given a bunch of documents about exercises for elder people where we had to extract the information.&lt;/p></description></item><item><title>Grid Power Optimization</title><link>https://bernatbc.tk/posts/education/localsearch/</link><pubDate>Mon, 24 Oct 2022 06:00:23 +0600</pubDate><guid>https://bernatbc.tk/posts/education/localsearch/</guid><description>&lt;h2 id="the-statement">The statement&lt;/h2>
&lt;p>Given a set of Power plants and Clients, find an assignation for each Client where the total benefit is the maximum. Each power plant is represented by coordinates in a map, the total production and the cost when it&amp;rsquo;s stopped and running. Each client is represented by coordinates in a map, the power consumed, the price it pays for each Mw and a compensation in the case he doesn&amp;rsquo;t get power. Also, power gets drained if the distance between a power plant and a client is farther than a certain value.&lt;/p></description></item></channel></rss>